{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"auto_encoder_12_optimization.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNSZ6HUSsqxtf1ASEu1jyv/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3lBzGPIwagio"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kQUCULS2jM9"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator and then re-execute this cell.')\n","else:\n","    print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEzp9pZG2mwC"},"source":["from psutil import virtual_memory\n","\n","ram = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM.'.format(ram))\n","if ram < 20:\n","    print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\", then select High-RAM in the Runtime shape dropdown '\n","          'and then re-execute this cell.')\n","else:\n","    print('You are using a high-RAM runtime.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ts94ZSjG2ou2"},"source":["from tensorflow import config\n","\n","physical_devices = config.list_physical_devices('GPU')\n","try:\n","    config.experimental.set_memory_growth(physical_devices[0], True)\n","except Exception as exception:\n","    print(exception)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBS0z95JDyn4"},"source":["from tensorflow import device\n","from tensorflow.keras import layers\n","from tensorflow.keras import losses\n","from tensorflow.keras import models\n","from tensorflow.keras import optimizers\n","\n","import csv\n","import datetime\n","import gc\n","import h5py\n","import numpy as np\n","import os\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YxdAbGVGiID"},"source":["berlin_files = '/content/gdrive/My Drive/Licenta/Traffic4Cast/Berlin/files/training'\n","istanbul_files = '/content/gdrive/My Drive/Licenta/Traffic4Cast/Istanbul/files/training'\n","moscow_files = '/content/gdrive/My Drive/Licenta/Traffic4Cast/Moscow/files/training'\n","\n","checkpoints = '/content/gdrive/My Drive/Licenta/Traffic4Cast/All/checkpoints/auto_encoder_12'\n","logs = '/content/gdrive/My Drive/Licenta/Traffic4Cast/All/logs/auto_encoder_12/training/logs.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKsRLhYg7zdP"},"source":["def get_file_names(berlin_files, istanbul_files, moscow_files):\n","    file_names = os.listdir(berlin_files) + os.listdir(istanbul_files) + os.listdir(moscow_files)\n","    np.random.shuffle(file_names)\n","    return file_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRvxv67PydA9"},"source":["def load_data(file_path):\n","    file = h5py.File(file_path, 'r')\n","    group_key = list(file.keys())[0]\n","    data = np.array(file[group_key][:], dtype=np.float32)\n","    file.close()\n","    data = np.take(data, np.arange(8), axis=-1)  # keep only the dynamic channels\n","    data = np.array(np.split(data, 12))  # 12 * (12 + 12) = 288\n","    np.random.shuffle(data)  # shuffle the 12 batches\n","    return data / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JEphNWvDdpd"},"source":["with device('gpu:0'):\n","    model = models.load_model(os.path.join(checkpoints, 'model_1.h5'))\n","    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.mean_squared_error)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqHEamlAHc6A"},"source":["file_names = get_file_names(berlin_files, istanbul_files, moscow_files)\n","\n","log_file = open(logs, 'w', newline='')\n","log_writer = csv.writer(log_file)\n","log_writer.writerow(['epoch', 'file', 'loss'])\n","log_file.flush()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MqdV979ao-G"},"source":["for epoch in range(2, 4):\n","    print('epoch:', epoch)\n","    for index, file_name in enumerate(file_names):\n","        print('file:', index)\n","        if 'berlin' in file_name:\n","            data = load_data(os.path.join(berlin_files, file_name))\n","        elif 'istanbul' in file_name:\n","            data = load_data(os.path.join(istanbul_files, file_name))\n","        else:\n","            data = load_data(os.path.join(moscow_files, file_name))\n","        losses = np.zeros(shape=(4,), dtype=np.float64)\n","        for batch in range(0, 12, 3):\n","            inputs = data[batch:batch + 3, :12]\n","            outputs = data[batch:batch + 3, 12:]\n","            with device('gpu:0'):\n","                history = model.fit(inputs, outputs, epochs=1, batch_size=1)\n","                losses[batch // 3] = history.history['loss'][0]\n","        log_writer.writerow([epoch, file_name, np.mean(losses, dtype=np.float64)])\n","        log_file.flush()\n","        gc.collect()\n","    model.save(os.path.join(checkpoints, 'model_{}.h5'.format(epoch)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24oZN5GMqgmY"},"source":["log_file.close()"],"execution_count":null,"outputs":[]}]}