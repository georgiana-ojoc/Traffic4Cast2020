{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq3_optimization.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMwd01Cne4IPtB3BgvoQG4N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3lBzGPIwagio"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kQUCULS2jM9"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator and then re-execute this cell.')\n","else:\n","    print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEzp9pZG2mwC"},"source":["from psutil import virtual_memory\n","\n","ram = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM.'.format(ram))\n","if ram < 20:\n","    print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\", then select High-RAM in the Runtime shape dropdown '\n","          'and then re-execute this cell.')\n","else:\n","    print('You are using a high-RAM runtime.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ts94ZSjG2ou2"},"source":["from tensorflow import config\n","\n","physical_devices = config.list_physical_devices('GPU')\n","try:\n","    config.experimental.set_memory_growth(physical_devices[0], True)\n","except Exception as exception:\n","    print(exception)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBS0z95JDyn4"},"source":["from tensorflow import device\n","from tensorflow.keras import layers\n","from tensorflow.keras import losses\n","from tensorflow.keras import models\n","from tensorflow.keras import optimizers\n","\n","import csv\n","import datetime\n","import gc\n","import h5py\n","import numpy as np\n","import os\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YxdAbGVGiID"},"source":["town = 'Berlin'  #@param ['Berlin', 'Istanbul', 'Moscow']\n","\n","files = '/content/gdrive/My Drive/Licenta/Traffic4Cast/{}/files/training'.format(town)\n","checkpoints = '/content/gdrive/My Drive/Licenta/Traffic4Cast/{}/checkpoints/seq2seq3'.format(town)\n","logs = '/content/gdrive/My Drive/Licenta/Traffic4Cast/{}/logs/seq2seq3/training/logs.csv'.format(town)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTvNuMjX8xnR"},"source":["def get_date(file_name):\n","    match = re.search(r'\\d{4}-\\d{2}-\\d{2}', file_name)\n","    return datetime.datetime.strptime(match.group(), '%Y-%m-%d').date()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKsRLhYg7zdP"},"source":["def get_file_names(files, excluded_dates=[]):\n","    file_names = os.listdir(files)\n","    np.random.shuffle(file_names)\n","    excluded_dates = [datetime.datetime.strptime(excluded_date, '%Y-%m-%d').date() for excluded_date in excluded_dates]\n","    file_names = [file_name for file_name in file_names if get_date(file_name) not in excluded_dates]\n","    return file_names[:45]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRvxv67PydA9"},"source":["def load_data(file_path):\n","    file = h5py.File(file_path, 'r')\n","    group_key = list(file.keys())[0]\n","    data = np.array(file[group_key][:], dtype=np.float32)\n","    file.close()\n","    data = np.take(data, np.arange(8), axis=-1)  # keep only the dynamic channels\n","    data = np.array(np.split(data, 48))  # 48 * (3 + 3) = 288\n","    data = np.moveaxis(data, -1, 2)  # transpose to (batches, timestamps, channels, rows, columns)\n","    np.random.shuffle(data)  # shuffle the 48 batches\n","    return data / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JEphNWvDdpd"},"source":["with device('gpu:0'):\n","    model = models.load_model(os.path.join(checkpoints, 'model_3.h5'))\n","    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.mean_squared_error)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqHEamlAHc6A"},"source":["log_file = open(logs, 'a', newline='')\n","log_writer = csv.writer(log_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MqdV979ao-G"},"source":["for epoch in range(4, 8):\n","    print('epoch:', epoch)\n","    file_names = get_file_names(files)\n","    for index, file_name in enumerate(file_names):\n","        print('file:', index)\n","        data = load_data(os.path.join(files, file_name))\n","        inputs = data[:, :3]\n","        outputs = data[:, 3:]\n","        with device('gpu:0'):\n","            history = model.fit(inputs, outputs, epochs=1, batch_size=3)\n","        log_writer.writerow([epoch, file_name, history.history['loss'][0]])\n","        log_file.flush()\n","        gc.collect()\n","    model.save(os.path.join(checkpoints, 'model_{}.h5'.format(epoch)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24oZN5GMqgmY"},"source":["log_file.close()"],"execution_count":null,"outputs":[]}]}